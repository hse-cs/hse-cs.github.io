[
  {
    "title": "LaNeta",
    "url": "https://github.com/hse-cs/LaNeta",
    "desc": "Библиотека для оценки времен примешивания между двумя популяциями при двух пульсах миграции. Метод построен на математической теории неравновесного сцепления трех генетических локусов при примешивании популяций. Он позволяет точно исследовать недавнюю (в пределах нескольких десятков поколений) историю примешивания популяций в сложных сценариях, для которых существовавшие ранее методы были неприменимы или неточны. Библиотека будет интересна всем, кто занимается популяционной геномикой. |",
    "links": [
      {
        "type": "paper",
        "href": "https://doi.org/10.1371/journal.pgen.1010281"
      },
      {
        "type": "code",
        "href": "https://github.com/hse-cs/LaNeta"
      }
    ]
  },
  {
    "title": "Fulu",
    "url": "https://github.com/hse-cs/fulu",
    "desc": "Библиотека для python, в которой собраны несколько методов для аппроксимации кривых блеска астрономических объектов с использованием машинного обучения. В библиотеке имплементирован алгоритм на основе гауссовских процессов, а так же некоторые другие, с использованием нормализующих потоков и баесовских сетей. Библиотека будет полезна астрономам и прикладным исследователям на стыке машинного обучения и астрофизики. |",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/hse-cs/fulu"
      },
      {
        "type": "paper",
        "href": "https://doi.org/10.1051/0004-6361/202245189"
      }
    ]
  },
  {
    "title": "Probaforms",
    "url": "https://github.com/hse-cs/probaforms",
    "desc": "В этой библиотеке имплементированы несколько архитектур условных генеративных моделей, включая, CVAE, WGAN, Real NVP. Интерфейс, схожий с интерфейсом библиотеки sklearn, позволяет быстро реализовать и проверять идеи. Инструмент ориентирован на работу с табличными данными и подойдет для различных инженерных и научных задач и приложений.",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/hse-cs/probaforms"
      }
    ]
  },
  {
    "title": "Linda",
    "url": "https://github.com/hse-cs/LINDA",
    "desc": "Библиотека на python, предназначенная для генерации синтетических табличных данных. В библиотеке реализованы несколько глубоких генеративных моделей. Модели выучивают статистические свойства входных данных и сохраняют эти свойства в синтетически сгенерированных. Библиотека может быть полезна аналитикам данных, инженерам и исследователям, занимающимся табличными и/или синтетическими данными.",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/hse-cs/LINDA"
      }
    ]
  },
  {
    "title": "TabDDPM",
    "url": "https://github.com/yandex-research/tab-ddpm",
    "desc": "Статья сотрудников лаборатории Яндекс, в которой исследуется применимость диффузионных моделей для задач генерации синтетических табличных данных. Авторы сравнивают свою работу с многочисленными бейзлайнами - VAE и GAN-ми. Для этого они семплируют синтетические данные из генеративных моделей и затем обучают на этих данных классические модели: случайный лес, CatBoost и т.п. Авторы показывают, что их метод обходит другие по качеству в различных сценариях, в том числе в сценарии защиты приватных данных. Работа может быть полезна исследователем, МЛ инженерам и аналитикам данных. |",
    "links": [
      {
        "type": "paper",
        "href": "https://proceedings.mlr.press/v202/kotelnikov23a/kotelnikov23a.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/tab-ddpm"
      }
    ]
  },
  {
    "title": "Star-shaped DDPM",
    "url": "https://github.com/andrey-okhotin/star-shaped/tree/main",
    "desc": "Статья, выполненная в коллаборации коллег из Bayesgroup с другими научными центрами. Авторы исследуют возможность обучения диффузионных моделей с использованием распределений, отличных от гауссовского. Для этого они показывают дуальность между диффузионным процессом в виде звезды (star-shaped) и обычным марковским процессом. Это позволяет получать эффективные алгоритмы для тренировки и семплирования диффузионных моделей в случае, если данные лежат на ограниченном многообразии. В своих экспериментах исследователи показывают состоятельность своей гипотезы, проверяя ее на простых синтетических данных, а также на гео- и картиночных данных. Работа будет полезна исследователям, чьи научные интересы лежат в сфере генеративных моделей, а так же ML-инженерам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1fcefa894924bb1688041b7a26fb8aea-Paper-Conference.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/andrey-okhotin/star-shaped"
      }
    ]
  },
  {
    "title": "gflownet-rl",
    "url": "https://github.com/d-tiapkin/gflownet-rl",
    "desc": "Статья коллег их HDI lab и Bayesgroup на стыке генеративного моделирования и обучения с подкреплением. В статье исследуется относительно новый подход в генеративном моделировании — GenerativeFlowNetworks. В своих экспериментах авторы сравнивают предложенный подход к обучению — через алгоритм M-DQN — с предыдущими работами по GFlowNets. В результате обученная модель оказывается не только конкурентной, но и показывает превосходство в ряде случаев. Статья может быть полезна исследователям из областей обучения с подкреплением и глубоких генеративных моделей, математикам и DL-инженерам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://publications.hse.ru/pubs/share/direct/935544431.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/d-tiapkin/gflownet-rl"
      }
    ]
  },
  {
    "title": "MARS",
    "url": "https://github.com/MaxBourdon/mars",
    "desc": "В статье описывается новый метод, позволяющий выбирать наиболее оптимальный ранг для тензорного разложения, помогая разрешать компромисс между уровнем сжатия и точностью. Идея метода заключается в выучивании бинарных масок, накрывающих ядра разложения с последующим выбором тех из них, что дают наивысшее качество. В своей работе авторы демонстрируют состоятельность метода, экспериментально подтверждая эффективность сжатия с минимальными потерями в точности для оптимизированной нейросети. Работа может быть полезна математикам, исследователям в области сжатия информации, вычислительной линейной алгебры и глубинного бучения, а также DL и LLMOps инженерам, |",
    "links": [
      {
        "type": "paper",
        "href": "https://proceedings.mlr.press/v206/kodryan23a/kodryan23a.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/MaxBourdon/mars"
      }
    ]
  },
  {
    "title": "wu-go",
    "url": "https://github.com/ramazyant/wu-go",
    "desc": "Статья коллег из лаборатории методов анализа больших данных LAMBDA, в которой исследуется применимость метрики Вассерштайна для оценки неопределенности безградиентной оптимизации black-box симуляторов. В работе авторы используют концепцию Вассерштайновских шаров для определения множества неопределенности (ambiguity set) и глубоких порождающих моделей для оптимизации сигнала симулятора. Состоятельность алгоритма подтвержддается множеством экспериментов как с простыми функциями, так и со сложными многомерными реальными данными с физических экспериментов. Работа может быть полезна физикам, дата аналитикам, математикам и ML исследователям. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2407.11917"
      },
      {
        "type": "code",
        "href": "https://github.com/ramazyant/wu-go/tree/main"
      }
    ]
  },
  {
    "title": "Roerich",
    "url": "https://github.com/HSE-LAMBDA/roerich",
    "desc": "Библиотека на python для онлайн и офлайн обнаружения точек разладки для анализа временных рядов. Точка разладки - это момент времени, в котором меняется поведение временного ряда, который характеризует наблюдаемую систему. Библиотека названа в честь Николая Рериха и содержит как известные методы, так и алгоритмы из недавно опубликованных работ. Этот инструмент может быть полезен дата аналитикам, физикам, инженерам и исследователям машинного обучения, специализирующихся на временных рядах.",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/HSE-LAMBDA/roerich/tree/main"
      }
    ]
  },
  {
    "title": "TabR",
    "url": "https://github.com/yandex-research/tabular-dl-tabr",
    "desc": "Код исследователей НУЛ Яндекса, в котором описывается новый алгоритм для улучшения качества глубоких нейронных сетей в задачах обучения с учителем на табличных данных. Основная идея метода - использование моделей с расширенным поиском (retrieval-augmented models). Для целевого объекта такие модели извлекают другие объекты (например, ближайших соседей) из доступных обучающих данных и используют их признаки и метки для лучшего прогнозирования. Авторы исследуют и предлагают улучшенный способ поиска похожего объекта, который позволяет повысить качество полносвязанных нейронных сетей на задачах регрессии и классификации. Исследователи экспериментально показыват, что метод превосходит по качеству LightGBM, XGBoost, CatBoost и другие популярные алгоритмы в ряде классических задач и бенчмарков. Работа может быть полезна ML-инженерам и исследователям, которые работают с табличными данными. |",
    "links": [
      {
        "type": "paper",
        "href": "https://openreview.net/pdf?id=rhgIgTSSxW"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/tabular-dl-tabr"
      }
    ]
  },
  {
    "title": "MegNetSparse",
    "url": "https://github.com/HSE-LAMBDA/MEGNetSparse",
    "desc": "Двумерные материалы перспектиыны для развития следующего поколения (опто-) электронных устройств. Основной характеристикой двумерных кристаллов является возможность настройки их свойств посредством контролируемого введения дефектов. Однако пространство поиска для таких структур огромно и требует больших вычислений. В библиотеке на python MegNetSparse реализован метод представлений таких двумерных кристаллов, который улучшает качество алгоритмов машинного обучения. Нейронные сети и CatBoost, обученные на этих представлениях, показаывают снижение ошибки прогнозирования энергии минимум в 3.7 раза. Кроме того, представленный подход на порядок более эффективен с точки зрения ресурсов, чем его конкуренты как в части обучения, так и инференса. Работа может быть полезна инженерам, физикам и исследователям в областе новых материалов. |",
    "links": [
      {
        "type": "paper",
        "href": "https://doi.org/10.1038/s41524-023-01062-z"
      },
      {
        "type": "code",
        "href": "https://github.com/HSE-LAMBDA/MEGNetSparse"
      }
    ]
  },
  {
    "title": "ARD-EM",
    "url": "https://github.com/hse-cs/ard-em",
    "desc": "Реализация ARD (Automatic Relevance Determination) EM на Python. Классический ЕМ-алгоритм восстановления смеси нормальных распределений не позволяет определять количество компонент смеси. В работе предлагается алгоритм автоматического определения числа компонент ARD EM, основанный на методе релевантных векторов. Идея алгоритма состоит в использовании на начальном этапе заведомо избыточного количества компонент смеси с дальнейшим определением релевантных компонент с помощью максимизации правдоподобия. Эксперименты на модельных задачах показывают, что количество найденных кластеров либо совпадает с истинным, либо немного превосходит его. Кроме того, кластеризация с помощью ARD EM оказывается ближе к истинной, чем у аналогов. Код может быть полезен ML-исследователям, физикам и инженерам для задач кластеризации и восстановления распределения данных |",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/hse-cs/ard-em"
      },
      {
        "type": "paper",
        "href": "http://pzs.dstu.dp.ua/DataMining/em/bibl/Vetrov-ArdEm-JVMMF-2009.pdf"
      }
    ]
  },
  {
    "title": "VGsim",
    "url": "https://github.com/Genomics-HSE/VGsim",
    "desc": "Библиотека для Python, предназначенная для моделирования вирусных генеалогий (VGsim — Viral Genealogy Simulator), с помощью которого можно моделировать пути распространения COVID-19 в условиях глобальной пандемии и прочие сценарии пандемий мирового масштаба. Симулятор вирусных генеалогий — программное обеспечение, предназначенное для проверки методов анализа данных, связанных с генетической природой коронавируса. По генетическим последовательностям вирусов можно детально проследить пути их распространения — построить их генеалогию, дерево заражений. Такие деревья содержат много информации, в частности, об эволюции патогенов. Авторы отмечают, что их библиотека не только является самым быстрым симулятором вирусных генеалогий, но так же способна учитывать миграцию, что отличает ее от общерпинятых моделей. Библиотека может быть полезна ученым-эпидемиологам, data science специалистам в области медицины и статистики. |",
    "links": [
      {
        "type": "paper",
        "href": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8095227/"
      },
      {
        "type": "code",
        "href": "https://github.com/Genomics-HSE/VGsim"
      }
    ]
  },
  {
    "title": "CartPole",
    "url": "https://github.com/robotics-laboratory/cart-pole",
    "desc": "Студенческий проект, предназначенный для изучения основ робототехники и теории управления, написанный на python и C++. Репозиторий содержит код для окружающей среды, которая представляет собой некоторую вариацию классической задачи cart-pole, описанной Барто, Саттоном и Андерсоном. Шарнир прикрепляет шест к тележке, которая движется вдоль направляющей оси. Некий шаговый двигатель приводит тележку в движение. Цель управления — желаемое ускорение тележки. Тележка начинает движение посередине без скорости или ускорения. Изначально шест находится в состоянии покоя. Задача — поднять шест и удерживать его в вертикальном положении, увеличивая и уменьшая скорость тележки. Код содержит интерфейс и для симулятора среды, и для контроллера, позволяя обучать модель и запускать ее на конечном устройстве, которое должно будет управлять вагонеткой. Проект может быть полезен студентам и энтузиастам, не только изучающим основы робототехники, но и уже имеющим схожий опыт, а так же инженерам, работающим со встраиваемыми устройствами.",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/robotics-laboratory/cart-pole"
      }
    ]
  },
  {
    "title": "Procfiler",
    "url": "https://github.com/PM-IDE/Procfiler",
    "desc": "— это инструмент, целью которого является устранение разрыва между .NET и Process Mining. В нем поддерживается сбор событий CLR (ETW) через EventPipe, а также различные экземпляры процессов (вызов метода, выполнение всей программы) и сериализация полученных журналов событий в разные форматы, в частности в XES. Затем журналы событий XES можно анализировать с помощью различных инструментов Process Mining, таких как ProM или pm4py. Более того, предложенный метод позволяет просматривать события на разных уровнях абстракции, тем самым увеличивая количество обнаруживаемых закономерностей и действий. В статье также описана серия экспериментов, проведенных для оценки предлагаемого метода обнаружения активности. Библиотека может быть полезна разработчикам и системным аналитикам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://link.springer.com/article/10.1007/s10515-024-00441-0"
      },
      {
        "type": "code",
        "href": "https://github.com/PM-IDE/Procfiler"
      }
    ]
  },
  {
    "title": "TIRE",
    "url": "https://github.com/hse-cs/TIRE_pytorch",
    "desc": "Библиотека на Python, реализующий метод поиска точек разладки для временных рядов на основе автоэнкодера. Алгоритмы для поиска таких точек, использующие подходы с глубинным обучением, часто не способны обнаружить и верно идентифицировать небольшие изменения, а также страдают от большой частоты ложноположительных срабатываний. Для борьбы с этими проблемами авторы предлагают использовать автокодироващик вместе с модифицированной функцией потерь, которая позволяет выучивать представления, инвариантные ко времени. Дополнительно авторы упоминают по постпроцессинг, значительно улучшающий качество не только представленного метода, но и базовых алгоритмов. Гибкость метода позволяет выбирать на инференсе, в какой области искать разладку: по времени, частоте или везде сразу. Авторы демонстрируют состоятельность своего метода на ряде синтетических и реальных данных, иногда превосходя бейзлайны. Работа может быть полезна инженерам, финансистам, machine learning инженерам и исследователям области временных рядов. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2008.09524"
      },
      {
        "type": "code",
        "href": "https://github.com/hse-cs/TIRE_pytorch"
      }
    ]
  },
  {
    "title": "GP-VAE",
    "url": "https://github.com/ratschlab/GP-VAE",
    "desc": "Модель для вероятностного заполнения пропусков во временных рядах. Авторы работы сравнивают свой подход с классическими моделями глубинного обучения для решения задачи заполнения пропусков, решая проблему ненадежности и малой интерпоетируемости последних. Модель со скрытыми переменными предполагает, что многомерные данные имеют низкоразмерное представление, изменяющиеся с течением времени согласно гауссовскому процессу. Нелинейное снижение размерности пропущенных данных достигается с помощью подхода VAE с новым структурированным вариационным приближением. В экспериментальной части исследователи демонстрируют, что такой подход превосходит несколько классических нейросетевых моделей заполнения пропусков для многомерных данных разной модальности, одновременно предоставляя интерпретируемые оценки неопределенности. Код может быть полезен data science специалистам и исследователям, работающим с временными рядами. |",
    "links": [
      {
        "type": "paper",
        "href": "https://proceedings.mlr.press/v108/fortuin20a/fortuin20a.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/ratschlab/GP-VAE"
      }
    ]
  },
  {
    "title": "Linguacodus",
    "url": "https://github.com/ketrint/Linguacodus",
    "desc": "Фреймворк, использующий большие языковые модели для автоматизации преобразования описания задач в код Python. Linguacodus решает эту задачу путем развертывания динамического конвейера, который итеративно преобразует описания задач на естественном языке в код с помощью высокоуровневых инструкций на основе данных. Фреймворк работает в 4 этапа: генерация описания задачи, где модель описывает данные, препроцессинг, архитектуру модели и прочие важные детали; тюнинг Llama2 на основе полученной информации; инференс Llama2, позволяющий отобрать три лучшие инструкции; и итеративный процесс улучшения ответов с помощью мульти-агентной языковой модели. В серии экспериментов на датасете с кодом для машинного обучения авторы демонстрируют эффективность своего метода по генерации кода. Фреймворк будет полезен как исследователям в области языковых моделей и генерации кода, так и прикладным специалистам машинного обучения. |",
    "links": [
      {
        "type": "paper",
        "href": "https://peerj.com/articles/cs-2328/"
      },
      {
        "type": "code",
        "href": "https://github.com/ketrint/Linguacodus"
      }
    ]
  },
  {
    "title": "StyleFeatureEditor",
    "url": "https://github.com/airi-institute/stylefeatureeditor",
    "desc": "Библиотека на Python, позволяющая обучать модель для редактирования изображения. В основе работы лежит новый подход к обучению StyleGan, позволяющий одновременно редактировать изображения в мало- и высокоразмерном пространствах, благодаря чему появляется возможность получать желаемые тонкие детали у редактируемого изображения и вместе с этим сохранить их при обратном переходе в исходное пространство. Авторы демонстрируют превосходное качество подхода даже для сложных, внедоменных изображений, добиваясь практически неотличимого правдоподобия полученных изображений, а также обходя в численных метриках другие методы. Код может быть полезен исследователям в области генеративных моделей и разработчикам приложений для редактирования фотографий. |",
    "links": [
      {
        "type": "paper",
        "href": "http://openaccess.thecvf.com//content/CVPR2024/papers/Bobkov_The_Devil_is_in_the_Details_StyleFeatureEditor_for_Detail-Rich_StyleGAN_CVPR_2024_paper.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/airi-institute/stylefeatureeditor"
      }
    ]
  },
  {
    "title": "gen-simplicial-cycles",
    "url": "https://github.com/ml-in-algebraic-topology/gen-simplicial-cycles",
    "desc": "Код на python, в котором реализованы некоторые классические, а так же авторские алгоритмы, основанные на llm, позволяющие генерировать циклы в симплициальных группах. В частности, в симплициальной групповой настройке формулы Ву авторы переформулируют проблему генерации симплициальных циклов как проблему выборки из пересечения алгоритмических наборов данных, связанных с языками Дика. Исследователи представляют и оценивают подходы к языковому моделированию, которые используют многометковую информацию для входных последовательностей и большие языковые модели, вместе с необходимым теоретико-групповым инструментом и не нейросетевыми базовыми алгоритмами. Построенные на идее ансамблирования генераторов, дополнительная многометковая информация добавляется в обучающий набор данных, что позволяет одной модели работать как обобщение ансамбля. Полученные авторами модели, в отличие от базовых, масштабируемы и будут служить строительными блоками для будущих алгоритмов, специализированных на выборке из гомотопических групп пространств. Код может быть полезен математикам и DL-исследователям, работающим на стыке машинного обучения и топологии. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/abs/2306.16951"
      },
      {
        "type": "code",
        "href": "https://github.com/ml-in-algebraic-topology/gen-simplicial-cycles"
      }
    ]
  },
  {
    "title": "«Введение в GIT»",
    "url": "https://cs.hse.ru/dpo/gitcourse/?utm_source=telegram&amp;utm_medium=opencode_channel&amp;utm_campaign=git_update",
    "desc": "Бесплатный онлайн-курс по Git Центр непрерывного образования факультета компьютерных приглашает присоединиться к бесплатному онлайн-курсу тех, кто начинает свой путь в программировании и разработке. Курс состоит из 5 уроков: - Что такое Git? - Добавление изменений в коммит и загрузка на удалённый репозиторий - Управление изменениями, отмена операций, выбор определённого коммита - Работа с ветками в репозитории - Слияние веток, merge и rebase, политики работы с ветками В Центре непрерывного образования в онлайн-формате можно освоить и другие навыки, необходимые для входа в IT: Python, SQL, инструменты бизнес-аналитики. У курсов есть бесплатные модули, к которым вы можете присоединиться уже сейчас. Подробная информация: .",
    "links": [
      {
        "type": "link",
        "href": "https://t.me/+hQGdqi1PvUc3MWEy"
      },
      {
        "type": "link",
        "href": "https://cs.hse.ru/dpo/gitcourse/?utm_source=telegram&amp;utm_medium=opencode_channel&amp;utm_campaign=git_update"
      }
    ]
  },
  {
    "title": "Truth-O-Meter",
    "url": "https://github.com/bgalitsky/Truth-O-Meter-Making-ChatGPT-Truthful",
    "desc": "Разработанный на Python проект, позволяющий проверять достоверность сгенерированного большими языковыми моделями текста. Авторы приложения утверждают, что их метод позволяет детектировать галлюцинации и фактологические ошибки, производя веб-поиск по сгенерированному LLM тексту. После чего пользователь может получить скорректированный программой текст, подсвечивающий неточности и приводящий ссылки на достоверные источники в интернете. В серии работ авторы рассказывают о различных аспектах проекта, а так же проверяют состоятельность метода на датасете FEVER. Работа может быть полезна исследователям, работающими с генеративными и большими языковыми моделями, инженерам и Data Science специалистам. ||",
    "links": [
      {
        "type": "paper",
        "href": "https://dl.acm.org/doi/10.1145/3626772.3657679"
      },
      {
        "type": "code",
        "href": "https://github.com/bgalitsky/Truth-O-Meter-Making-ChatGPT-Truthful"
      },
      {
        "type": "demo",
        "href": "http://84.201.175.11:8765/"
      }
    ]
  },
  {
    "title": "Guide-and-rescale",
    "url": "https://github.com/MACderRu/Guide-and-Rescale",
    "desc": "Код, позволяющий тренировать и инференсить диффузионную модель, способную редактировать изображение по текстовому запросу. В своей работе авторы исследуют метод гайденса для модели, благодаря которой траектория, вдоль которой семплируюется шум в диффузионной модели, не выходит из реального распределения данных. Это, в свою очередь, позволяет получить качественные и реалистичные изображения. Для достижения результата авторы вводят специальные энергетические функции, сохраняющие локальные свойства объектов на изображениях. Исследователи утверждают, что их подход эффективен с точки зрения вычислений, а так же показывают в ряде экспериментов его состоятельность. Код может быть полезен DL-исследователям, Data Science специалистам и ML-инженерам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2409.01322"
      },
      {
        "type": "code",
        "href": "https://github.com/MACderRu/Guide-and-Rescale?tab=readme-ov-file"
      }
    ]
  },
  {
    "title": "Truck",
    "url": "https://github.com/robotics-laboratory/truck",
    "desc": "Проект с открытым исходным кодом, посвященный созданию и развитию 2.5D автономного транспортного средства на основе модели рулевого управления Аккермана, рассчитанного на пользование внутри помещения. Для перемещения робот использует систему лидаров, данные с которых затем обрабатываются нейросетями на микрокомпьютере Jetson для точной и быстрой навигации. Для управления всей системой авторы сконструировали и запрограммировали контроллеры и микропроцессоры, учитывая кинематические и электротехнические особенности своего робота. Проект может быть интересен программистам микроконтроллеров, специалистам по робототехнике, инженерам-разработчикам беспилотного транспорта, специалистам по машинному и глубокому обучению, а так же студентам, заинтересованным в изучении этих дисциплин.",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/robotics-laboratory"
      }
    ]
  },
  {
    "title": "TensorNorm",
    "url": "https://github.com/GrishKate/conv_norm",
    "desc": "Код на python, позволяющий считать и контролировать спектральную норму матрицы Якоби. Задача естественным образом возникает в обучении больших сверточных моделей. В своей работе авторы предлагают использовать тензоную спектральную норму для вычисления нормы всего сверточного слоя. Код вычисления нормы инвариантен к входному разрешению картинки и может быть эффективно вычислен во время обучения. В работе авторы выводят теоретическую верхнюю границу нормы, а в серии экспериментов показывают состоятельность метода, демонстрирую лучшую обобщающую способность моделей, регуляризированных с помощью данного подхода. Авторы также показывают, что их алгоритм показывает компромисс между точностью и скоростью вычисления. Код может быть полезен DL-исследователям разных областей и data-science специалистам. |",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/GrishKate/conv_norm"
      },
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2409.11859"
      }
    ]
  },
  {
    "title": "DAIseg",
    "url": "https://github.com/Genomics-HSE/DAIseg",
    "desc": "Код, реализующий точный метод DAIseg для определения участков генома с древним происхождением, унаследованных современными людьми от неандертальцев и денисовцев. Новизной метода является одновременное использование “внешней группы” - неперемешанной популяции и образцов известных древних геномов в одной модели. Авторы утверждают, что их методы превосходят ранее разработанные аналоги, такие как метод HMMMix. Работа может быть полезна для дата аналитиков, data science специалистов и исследователей популяционной генетики. |",
    "links": [
      {
        "type": "paper",
        "href": "https://link.springer.com/article/10.1134/S1995080224602959"
      },
      {
        "type": "code",
        "href": "https://github.com/Genomics-HSE/DAIseg"
      }
    ]
  },
  {
    "title": "GNN-Tox",
    "url": "https://github.com/li-xinze/GNN-Tox",
    "desc": "Код, позволяющий выполнить предобучение для графовой модели для прогноза свойств молекул. Предлагаемый авторами метод - Descriptor-base Graph Self-Supervised Learning - позволяет включать центры дескрипторов в задачу предобучения на уровне узлов, решая основные проблемы предшественников: отсутствие информации о домене во вспомогательных задачах на уровне узлов и высокая вычислительная сложность одновременного обучения для методов на основе мотивов и на уровне узлов. В серии экспериментов исследователи сравнивают свой подход с существующими бейзлайнами предобучения, демонстрируя существенно возросшее качество прогноза. Код может быть полезен исследователям графовых нейронных сетей, молекулярной биологии, DL-исследователям и DS-специалистам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10229129"
      },
      {
        "type": "code",
        "href": "https://github.com/li-xinze/GNN-Tox"
      }
    ]
  },
  {
    "title": "understanding-largre-lrs",
    "url": "https://github.com/isadrtdinov/understanding-large-lrs",
    "desc": "Репозиторий содержит код для обучения различных моделей компьютерного зрения в режиме предобучения с увеличенным learning rate (LR). Авторы работы исследуют влияние такого предобучения на финальное качество модели. Исследователи приходят к выводу, что предварительное обучение с умеренно большими LR, немного выше порога сходимости, позволяет получать наилучшие чекпоинты для последующего файнтюна или усреднения веса. С точки зрения геометрии обучение с этими значениями LR находит бассейн хорошо обобщающих решений в ландшафте функции потерь; с точки зрения обучения признаков эти решения соответствуют разреженному набору изученных признаков, которые наиболее полезны для задачи. Использование других значений LR может привести к неоптимальным результатам: либо нестабильным локальным минимумам, соответствующим плотному набору изученных признаков с меньшими LR, либо обширным областям с разнообразными минимумами и ухудшенным обучением признаков с большими LR. Код может быть полезен DL-исследователям, DS-специалистам и аналитикам данных. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2410.22113"
      },
      {
        "type": "code",
        "href": "https://github.com/isadrtdinov/understanding-large-lrs/"
      }
    ]
  },
  {
    "title": "Indecies-kmeans",
    "url": "https://github.com/glendawur/indices_kmeans",
    "desc": "Репозиторий содержит код для поиска оптимального количества кластеров К для алгоритма кластеризации k-средних. В своей работе авторы исследуют метод инерции, основанным на новом Elbow индексе для определения числа кластеров, валидируя результат по метрике Силуэт. Исследователи отмечают, что инерциальные индексы работают лучше всего при усреднении результатов нескольких запусков кластеризации, а не при выборе лучшего, как считалось ранее. В конце авторы замечают, что однозначно лучшего индекса для определения количества кластеров выявить не удалось. Индекс SW (ширина силуэта) обычно приводит к наиболее сбалансированным решениям. Тем не менее, индекс XU превосходит SW на синтетических данных с большими кластерными смесями, особенно для данных меньшей размерности. Код может быть полезен дата аналитикам и DS-специалистам, а так же исследователям в области машинного обучения. |",
    "links": [
      {
        "type": "paper",
        "href": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10382499"
      },
      {
        "type": "code",
        "href": "https://github.com/glendawur/indices_kmeans"
      }
    ]
  },
  {
    "title": "tabgraphs",
    "url": "https://github.com/yandex-research/tabgraphs",
    "desc": "Бенчмарк для обучения на графах для табличных данных с гетерогенными признаками-вершинами. Авторы оценивают большое количество моделей, включая стандартные бейзлайны и нейросетевые модели для графовых и табличных задач. В экспериментальной части исследователи показывают, что несколько ранее упускаемых из виду модификаций моделей, таких как аугментация признаков-вершин на основе соседства графа для графонезависимых табличных моделей или числовые эмебддинги признаков для GNN, позволяют достичь наилучшей производительности на таких данных. Работа может быть полезна DS-специалистам, а так же ML-исследователям, фокусирующимся на табличных данных или графовых моделях. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2409.14500"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/tabgraphs"
      }
    ]
  },
  {
    "title": "reparameterized-volume-sampling",
    "url": "https://github.com/GreatDrake/reparameterized-volume-sampling",
    "desc": "Имплементация end-to-end дифференцируемого метода по семплированию точек луча для задачи синтеза новых сцен из набора изображений. Метод основан на оценках Монте-Карло и позволяет улучшать иерархическую схему рендеринга, представленную в ставшей уже классической статье NeRF. В серии экспериментов авторы показывают превосходство подхода на этапе инференса, используя предобученную модель. Те же эксперименты выявляют проблемы метода при использовании во врем обучения модели. Исследователи утверждают, что их алгоритм семплинга улучшает реконструкцию сцен для иерархических моделей и упрощает процедуру обучения, позволяя избавиться от дополнительных слагаемых в функции потерь. Работа может быть полезна дизайнерам и DL-исследователям. |",
    "links": [
      {
        "type": "paper",
        "href": "https://proceedings.mlr.press/v238/morozov24a/morozov24a.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/GreatDrake/reparameterized-volume-sampling"
      }
    ]
  },
  {
    "title": "TabM",
    "url": "https://github.com/yandex-research/tabm?tab=readme-ov-file#using-tabm-in-practice",
    "desc": "Репозиторий, содержащий имплементацию TabM — модели, эффективно имитирующей ансамбль многослойных перцептронов для решения задач на табличных данных. Для этого вводятся специальные адаптеры - матрицы, чьи элементы равны ± 1. Эти адаптеры эффективно создают уникальные версии матрицы весов, за счет чего и имитируется ансамбль. В итоговой архитектуре такой адаптер применяется только ко всем копиям одного входа, которые затем подаются в линейные слои. В серии экспериментов авторы показывают существенное превосходство метода для задач на табличных данных по сравнению с другими классическими и нейросетевыми подходами, в том числе использующие механизм внимания. Модель также демонстрирует лучшую скорость обучения и инференса, уступая лишь стандартному MLP и XGBoost. Работа может быть полезна аналитикам, DS-специалистам и DL-исследователям. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2410.24210"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/tabm?tab=readme-ov-file#using-tabm-in-practice"
      }
    ]
  },
  {
    "title": "rtdl-num-embeddings",
    "url": "https://github.com/yandex-research/rtdl-num-embeddings",
    "desc": "Библиотека на python, позволяющая получать эмбеддинги для непрерывных признаков в задачах для табличных данных. Используемые вместо скалярных признаков эмбеддинги улучшают итоговое качество моделей на специфических задачах, при этом не увеличивая вычислительную сложность. В своей работе авторы представляют несколько алгоритмов получения эбмеддингов, а в экспериментальной части показывают состоятельность метода. В частности, сравнивая DL-алгоритмы с классическими подходами, такими как GBDT, на задачах, заточенных под последние. В таком режиме DL методы без использования эмебеддингов уступают классическим, а при использовании обходят их. Библиотека может быть полезна DS-специалистам, дата аналитикам и ML-инженерам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2203.05556"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/rtdl-num-embeddings?tab=readme-ov-file"
      }
    ]
  },
  {
    "title": "RATANSunPy",
    "url": "https://github.com/SpbfSAO/RATANSunPy",
    "desc": "Библиотека на python, разработанный для доступа, визуализации и анализа многополосных радионаблюдений Солнца с комплекса РАТАН-600. Эти данные представляют ценность для диагностики состояния солнечной плазмы и прогнозирования солнечной активности. Пакет предлагает комплексные функции обработки данных, включая прямой доступ к необработанным данным, основные этапы обработки, такие как калибровка и нормализация тихого Солнца, а также инструменты для анализа солнечной активности. Сюда входит автоматическое обнаружение локальных источников, идентификация их с активными областями NOAA и дальнейшее определение параметров для локальных источников и активных областей. Работа может быть полезна физикам, астрономам, и DS-специалистам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://www.sciencedirect.com/science/article/abs/pii/S2213133724001331"
      },
      {
        "type": "code",
        "href": "https://github.com/SpbfSAO/RATANSunPy"
      }
    ]
  },
  {
    "title": "structural-graph-shifts",
    "url": "https://github.com/yandex-research/structural-graph-shifts",
    "desc": "В работе рассматривается проблема оценки робастности моделей графовых нейронных сетей. Для оценки неопределенности прогноза в таких моделях используются различные подходы: общие, например, ансамблирование, и специфические, использующие свойства графовой структуры. Вне зависимости от метода оценки устойчивости модели, для его обучения необходимы данные, содержащие в себе различные источники неопределенностей, например, сдвиги распределений. Типичные датасеты для оценки робастности графовых нейронных сетей используют сдвиги на уровне признаков. Авторы предлагают более универсальный способ создания неопределенности в данных, основанный на особенностях графовых данных. В репозитории проекта содержится код, позволяющий получить подобные данные с различными видами неопределенности, а также имплементацию различных методов оценки неопределенности и улучшения робастности. В серии экспериментов авторы демонстрируют сложность, с которой сталкиваются модели в таком режиме обучения. При этом более простые модели часто превосходят в качестве прогноза продвинутые алгоритмы. Работа может быть полезна DL-исследователям, специалистам по графовым нейронным сетям, DS-специалистам и дата аналитикам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2302.13875"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/structural-graph-shifts/tree/main"
      }
    ]
  },
  {
    "title": "DeepZ",
    "url": "https://github.com/Nazar1997/DeepZ_MM",
    "desc": "Репозиторий содержит код и данные для обучения нейросетей для поиска и выявления паттернов в Z-ДНК генома человека и мышей. Вопрос о роли Z-ДНК в процессе транскрипции актуален для вычислительной биологии и медицины. Исследования роли Z-флипонов в процессе создания РНК-копий генов может помочь в разработке новых лекарств. При обучении учитывалась не только информация из линейной последовательности ДНК, но и данные из десятков тысяч омиксных экспериментов. Обученные модели - для человека и мыши - выявляют в последовательности ДНК участки, которые с наибольшей вероятностью являются Z-ДНК. Работа может быть полезна медикам, биологам, биоинженерам и фармакологам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://www.nature.com/articles/s41598-024-68439-y"
      },
      {
        "type": "code",
        "href": "https://github.com/Nazar1997/DeepZ_MM"
      }
    ]
  },
  {
    "title": "Mr.Handy",
    "url": "https://github.com/robotics-laboratory/handy",
    "desc": "Handy — проект с открытым исходным кодом на С++ и python, поддерживаемый HSE Robotics Group. Цель проекта — спроектировать и разработать роботизированный манипулятор, который сможет играть в настольный теннис. В репозитории есть код для считывания данных с камер, обучения и инференса модели для детекции шарика для тенниса, а так же для управления рукой-манипулятором. Весь код, наборы данных, модели и инструкции по разработке доступны и, как обещают авторы, всегда будут доступны онлайн. Следить за проектом можно в канале группы робототехники. Проект может быть полезен начинающим специалистам в области робототехники, машинного обучения и программирования микроконтроллеров. |",
    "links": [
      {
        "type": "code",
        "href": "https://github.com/robotics-laboratory/handy"
      },
      {
        "type": "link",
        "href": "https://t.me/robot_tales"
      }
    ]
  },
  {
    "title": "delPezzo",
    "url": "https://github.com/hse-cs/delPezzo",
    "desc": "Модуль для Sagemath для изучения гибкости аффинных конусов над поверхностями дель Пеццо. Код призван облегчать большинство операций для проверки общей гибкости аффинных конусов над поверхностями дель Пеццо и слабыми поверхностями дель Пеццо произвольной степени в зависимости от поляризации. Используя его, авторы проверили общую гибкость аффинных конусов над поляризациями поверхностей степени 1 при определенных условиях и над произвольными очень обильными поляризациями слабых поверхностей дель Пеццо степени 6. Репозиторий может быть полезен математикам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2305.06462"
      },
      {
        "type": "code",
        "href": "https://github.com/hse-cs/delPezzo"
      }
    ]
  },
  {
    "title": "vaidya-with-certificates",
    "url": "https://github.com/egorgladin/vaidya-with-certificates",
    "desc": "В репозитории представлен код для построения сертификатов точности — специальных вычислимых критериев останова в задачах выпуклой оптимизации — подходящих для методов отсечения плоскости, использующих многоугольники в качестве локализаторов. В качестве примера авторы приводят метод Вайдьи, являющийся асимптотически оптимальным с точки зрения вызова оракула. Численные эксперименты показывают превосходство представленного метода построения сертификатов по сравнению с бейзлайн подходом. В качестве причины такого феномена исследователи называют отличие в методах: описываемый алгоритм ищет сертификаты, напрямую максимизирующие функцию, используемую для ограничения остатка. Работа может быть полезна исследователям в области оптимизации, DL-исследователям и математикам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://link.springer.com/article/10.1007/s10957-024-02599-9"
      },
      {
        "type": "code",
        "href": "https://github.com/egorgladin/vaidya-with-certificates"
      }
    ]
  },
  {
    "title": "heterophilous-graphs",
    "url": "https://github.com/yandex-research/heterophilous-graphs",
    "desc": "В репозитории содержится код для воспроизведения результатов работы по критическому анализу оценки графовых нейронных сетей (GNN) на гетерофильных графах. Авторы выявили серьёзные недостатки популярных датасетов (squirrel, chameleon), включая дублирование узлов, что приводит к утечке данных между обучающей и тестовой выборками. Устранение дубликатов значительно снижает производительность моделей, меняя их ранжирование. Исследователи предлагают новые гетерофильные датасеты (roman-empire, amazon-ratings и др.), охватывающие различные домены и структурные свойства. Эксперименты показали, что стандартные GNN (например, GCN, GraphSAGE), особенно с модификацией разделения эго- и соседних эмбеддингов, часто превосходят специализированные модели для гетерофилии. Работа может быть полезна аналитикам данных, DL-исследователям и специалистам по графам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2302.11640"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/heterophilous-graphs"
      }
    ]
  },
  {
    "title": "btard",
    "url": "https://github.com/yandex-research/btard",
    "desc": "В репозитории представлен код для проведения безопасного распределённого обучения нейронных сетей с учетом атак Byzantine. Авторы предлагают новый протокол BTARD-SGD, который сочетает эффективность современных алгоритмов All‑Reduce с криптографическими методами проверки целостности данных.В работе проведён строгий теоретический анализ сходимости как для выпуклых, так и для невыпуклых задач, а также для случаев с тяжелыми хвостами распределения градиентов. Дополнительно предложена эвристика для защиты от Sybil‑атак, позволяющая новым участникам присоединяться к обучению только после демонстрации надёжности своих вычислений. Экспериментальная оценка включает обучение ResNet‑18 на CIFAR‑10 и предобучение ALBERT‑large, где предложенный протокол успешно противостоит различным типам атак (обратное знаковое, атаки случайным направлением, флиппинг меток, задержка градиентов и др.), позволяя быстро восстановить качество модели после атак. Работа может быть полезна исследователям в области распределённого обучения, специалистов по безопасности ИИ и разработчикам систем коллективного обучения, где важно объединять вычислительные ресурсы без риска компрометации результатов из-за недобросовестных участников. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2106.11257"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/btard"
      }
    ]
  },
  {
    "title": "CodeBuddy",
    "url": "https://github.com/LucyRez/CodeBuddy",
    "desc": "В репозитории содержится код для реализации сервиса генерации кода мобильных приложений (iOS/Android) на основе больших языковых моделей. Авторы адаптируют существующую модель (CodeQwen) с помощью тонкой настройки (PEFT, QLoRA), а также проводят собственное бенчмаркинговое тестирование, ориентированное на задачи мобильной разработки (Swift). Предложенная микросервисная архитектура включает несколько модулей (API Gateway, чат, авторизация, ИИ-модуль), что повышает масштабируемость и удобство интеграции. Авторы показывают, что такой сервис способен автоматически генерировать компоненты пользовательского интерфейса, бизнес-логику, а также код тестов, упрощая рутинные задачи разработчика. Работа может быть полезна разработчикам мобильных приложений, специалистам по генерации кода и исследователям, занимающимся применением больших языковых моделей в узкоспециализированных областях. |",
    "links": [
      {
        "type": "paper",
        "href": "https://publications.hse.ru/pubs/share/direct/1001817469.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/LucyRez/CodeBuddy"
      }
    ]
  },
  {
    "title": "LLM-Microscope",
    "url": "https://github.com/AIRI-Institute/LLM-Microscope",
    "desc": "В репозитории содержится код для экспериментов, показывающих линейность трансформеров. Авторы исследуют механизм, при котором соседние слои декодера (например, в GPT, LLaMA, OPT и BLOOM) оказываются почти линейно зависимыми. Используя Procrustes-метрику, показывается, что выходы последовательных слоев совпадают с точностью ~99% (но лишь при учёте residual connection). Исследователи демонстрируют, что нормировка выхода каждого блока относительно residual-части весьма мала, и это приводит к «линейности» между слоями. Кроме того, в работе изучаются задачи «прореживания» (pruning) слоёв на основе выявленной линейности и замены некоторых блоков их линейными аналогами без значимой потери в качестве. Предложены также регуляризационные приёмы на основе косинусной близости, снижающие линейность для повышения выразительности модели и улучшения результатов на ряде задач (TinyStories, SuperGLUE). Работа может быть полезна исследователям и практикам, занимающимся анализом внутренней структуры больших языковых моделей, а также LLM-инженерам, стремящимся к более эффективным моделям при сохранении качества. |",
    "links": [
      {
        "type": "paper",
        "href": "https://aclanthology.org/2024.acl-long.293/"
      },
      {
        "type": "code",
        "href": "https://github.com/AIRI-Institute/LLM-Microscope"
      }
    ]
  },
  {
    "title": "ai4material_design",
    "url": "https://github.com/HSE-LAMBDA/ai4material_design",
    "desc": "В репозитории приведён код, демонстрирующий эффективность подхода со «сжатым» представлением дефектов в двумерных материалах. Авторы отмечают, что 2D-кристаллы обладают колоссальным потенциалом для модификации их свойств путём контролируемого введения вакансий и замещений, однако большинство универсальных моделей плохо учитывают возникающие при этом квантовые эффекты. В работе предлагается рассматривать только атомы, непосредственно относящиеся к точечным дефектам (включая «виртуальные» атомы‑вакансии), и использовать графовые нейронные сети, дополненные специфичными для 2D-фаз признаками — разницей координат по оси z и новой меткой «EOS», связанной с осцилляциями электронных оболочек. Эксперименты показывают, что подход со «сжатым» представлением существенно превосходит классические графовые нейросети и методы с предварительными признаками. Авторы подчеркивают, что их метод значительно упрощает моделирование дефектных систем, повышая точность и эффективность. Работа может быть полезна инженерам, физикам и исследователям в областе новых материалов. |",
    "links": [
      {
        "type": "paper",
        "href": "https://www.nature.com/articles/s41524-023-01062-z"
      },
      {
        "type": "code",
        "href": "https://github.com/HSE-LAMBDA/ai4material_design"
      }
    ]
  },
  {
    "title": "SAE-Reasoning",
    "url": "https://github.com/AIRI-Institute/SAE-Reasoning",
    "desc": "Коллаборация ученных из АИРИ, ВШЭ, Сколтеха, МТУСИ и Сбера, посвященная интерпретации больших языковых моделей с помощью SAE - разреженных автоэнкдеров. В репозитории находится код, демонстрирующий, как SAE могут выявлять и корректировать специфические признаки рассуждения внутри больших языковых моделей. Авторы анализируют активации модели при генерации цепочек рассуждений, используя специальную метрику ReasonScore, которая показывает, насколько конкретная латентная компонента связана с логическими словами и фразами. Далее исследователи показывают, как выборочно усиливать такие признаки в процессе генерации: при steering повышается склонность модели к пошаговым объяснениям, перепроверке вычислений и более глубокому анализу. Эксперименты на ряде задач (например, MATH-500) подтверждают, что подобная тонкая настройка увеличивает как количество промежуточных выводов, так и общее качество ответа. Код может быть полезен специалистам, занимающимся интерпретацией внутренних представлений LLM, DL-инженерам и DS-специалистам |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2503.18878"
      },
      {
        "type": "code",
        "href": "https://github.com/AIRI-Institute/SAE-Reasoning"
      }
    ]
  },
  {
    "title": "rapid-ao",
    "url": "https://github.com/HSE-LAMBDA/rapid-ao",
    "desc": "В репозитории содержится код для воспроизведения экспериментов, описанных в работе про “Adaptive Divergence”, где ученные из лаборатории LAMBDA ФКН решают задачу быстрого согласования распределений в условиях дорогих симуляторов. Основная идея — использовать новое семейство «адаптивных расхождений», которое динамически регулирует мощность дискриминатора, переключаясь с «узких» моделей на «более сильные» лишь тогда, когда исходные распределения уже близки друг к другу. В частности, авторы демонстрируют, как это семейство ускоряет процедуру настройки высокоразмерных симуляторов с помощью чёрных ящиков. Репозиторий может быть полезен исследователям из физики, DL-инженерам и DS-специалистам |",
    "links": [
      {
        "type": "paper",
        "href": "https://peerj.com/articles/cs-274/"
      },
      {
        "type": "code",
        "href": "https://github.com/HSE-LAMBDA/rapid-ao"
      }
    ]
  },
  {
    "title": "digital-twin",
    "url": "https://github.com/HSE-LAMBDA/digital-twin",
    "desc": "В данном исследовании группа ученых из ВШЭ моделируют производительность систем хранения данных, используя вероятностный подход. Они рассматривают различные компоненты — кэш, SSD, HDD, — собирают показатели IOPS и задержки при разных конфигурациях и нагрузках, а затем обучают свои модели CatBoost и Normalizing Flow. Авторы демонстрируют, что этот подход не только предсказывает средние значения, но и охватывает всё распределение метрик, что особенно важно для оценки неопределенности и сценариев «цифрового двойника». Исследователи также проверяют надежность предсказаний с помощью известных зависимостей и отмечают, что полученные результаты тесно соответствуют реальным измерениям, превосходя простые методы вроде kNN. Данная методика может быть применена для анализа производительности, оптимизации настроек и предиктивного обслуживания систем хранения данных. Вклад авторов не ограничивается выбранным подходом: они также предоставляют открытый доступ к набору данных, использованному в исследовании. Найти его можно в репозитории с кодом. Работа может быть полезна ML-инженерам и DS-специалистам. |",
    "links": [
      {
        "type": "paper",
        "href": "https://ieeexplore.ieee.org/document/10930879"
      },
      {
        "type": "code",
        "href": "https://github.com/HSE-LAMBDA/digital-twin"
      }
    ]
  },
  {
    "title": "hogwild_llm",
    "url": "https://github.com/eqimp/hogwild_llm",
    "desc": "В репозитории содержится код для реализации и запуска параллельного инференса больших языковых моделей (LLM) по методу Hogwild! Inference — подхода, при котором несколько копий одной и той же модели выполняются параллельно и синхронизируются через общий attention-кэш. Вместо заранее заданной стратегии кооперации, модели сами решают, как разделить задачи, используя видимость токенов друг друга в общем KV-кэше и минимальную задержку при взаимодействии. Метод позволяет моделям в процессе инференса договариваться о стратегии: распределять подзадачи, исправлять ошибки других агентов, перепланировать ход решения. Для этого используются специальные конфигурации shared attention cache (contiguous, interleaved и combined), а также промптинг, стимулирующий модели проверять, не дублируют ли они работу друг друга. Эксперименты с открытыми LLM (например, QwQ-32B, DeepSeek-R1) показывают, что даже без дополнительного обучения модели способны обнаруживать дублирование, корректировать план решения и достигать сопоставимого или лучшего качества при меньшем количестве итераций. Кроме того, предложенная архитектура демонстрирует хорошее аппаратное ускорение за счёт снижения необходимости повторного вычисления attention-блоков. Код может быть полезен LLM-инженерам и исследователям, специалистам по агентам и DL исследователям. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2504.06261v2"
      },
      {
        "type": "code",
        "href": "https://github.com/eqimp/hogwild_llm"
      }
    ]
  },
  {
    "title": "MIGTF",
    "url": "https://github.com/hse-cs/MIGTF",
    "desc": "В репозитории содержится код для воспроизведения результатов работы по дополнению пропущенных связей в knowledge graph с использованием новой модели факторизации тензоров со смешанной геометрией (MIG-TF). Авторы предлагают подход, комбинирующий евклидову геометрию, через Tucker-разложение, и гиперболическую геометрию, через введённый гиперболический тернарный член взаимодействия TPTF. Такая конструкция позволяет более точно моделировать структурные особенности реальных knowledge graph, где распределение связей зачастую лишь частично следует иерархической структуре. В экспериментах показано, что предложенная модель превосходит по качеству как чисто евклидовые, так и чисто гиперболические модели, достигая state-of-the-art результатов на стандартных датасетах FB15k-237, YAGO3-10 и WN18RR при меньшем числе параметров. Особенно заметно улучшение на графах с нарушенной иерархией (например, FB15k-237). Кроме того, авторы изучают влияние кривизны гиперболической компоненты, вводят регуляризацию через ортогонализацию и анализируют робастность модели к зашумлённости обучающих данных. Работа может быть полезна исследователям в области factorization-based подходов к knowledge graph completion, а также специалистам, занимающимся построением компактных и эффективных моделей для анализа графовых данных со смешанной структурой. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2504.02589"
      },
      {
        "type": "code",
        "href": "https://github.com/hse-cs/MIGTF"
      }
    ]
  },
  {
    "title": "invertible-cd",
    "url": "https://github.com/yandex-research/invertible-cd",
    "desc": "В репозитории содержится код для реализации метода Invertible Consistency Distillation (iCD) — нового подхода к ускоренному текстово-ориентированному редактированию изображений с возможностью точной инверсии входного изображения. Исследователи из Яндекса и ВШЭ демонстрируют, что iCD позволяет выполнять как генерацию по текстовому описанию, так и обратное кодирование реального изображения в латентное пространство за 3–4 итерации, что делает метод пригодным для быстрой и реалистичной генерации и правок. Ключевым элементом является модифицированная схема consistency distillation с разделением на прямую и обратную модели, поддерживающими многопроходную инверсию. Дополнительно используется динамическое управление шкалой classifier-free guidance, что улучшает качество реконструкции без увеличения вычислительных затрат. Эксперименты на моделях SD1.5 и SDXL показывают, что iCD превосходит или сравним по качеству с SOTA-методами, такими как NTI, InfEdit, ReNoise, но работает в несколько раз быстрее: 8 шагов против 50–150 у конкурентов. Работа может быть полезна разработчикам инструментов для редактирования изображений, исследователям в области дистилляции диффузионных моделей и тем, кто разрабатывает быстрые пайплайны генерации и редактирования в условиях ограниченных ресурсов. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2406.14539"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/invertible-cd"
      }
    ]
  },
  {
    "title": "tencdm",
    "url": "https://github.com/M0RJIQUE/tencdm",
    "desc": "В репозитории содержится код для воспроизведения экспериментов по генерации текста методом TEncDM (Text Encoding Diffusion Model) — диффузионной модели, работающей в пространстве выходных представлений предобученной языковой модели, а не в embedding-пространстве, как в большинстве предыдущих работ. Авторы демонстрируют, что использование таких представлений, содержащих контекстную информацию, существенно упрощает задачу денойзинга и повышает качество генерации. Ключевая особенность TEncDM — декодер, специально обученный восстанавливать текст из зашумленных латентных представлений, что позволяет компенсировать ошибки на этапах диффузии. Также авторы подробно исследуют влияние self-conditioning и scheduler’ов шума на качество модели. Предложен новый scheduler (tan-d), равномерно распределяющий сложность по всем шагам денойзинга. В экспериментах показано, что при использовании таких компонентов модель превосходит существующие SOTA подходы (DiffuSeq, AR-Diffusion и др.) на задачах перефразирования, суммаризации и упрощения текста (QQP, XSum, Wiki-Auto). Репозиторий предоставляет полный пайплайн: тренировка диффузионной модели в пространстве энкодингов, обучение декодера с corrupt-стратегией, настройка self-conditioning и различных схем шумов. Код открытый, реализован на PyTorch и включает запуск на множестве датасетов (ROCStories, Wikipedia и др.), поддерживая генерацию в условиях как с условием (conditional), так и без него. Работа может быть полезна исследователям в области генерации текста, особенно тем, кто занимается развитием диффузионных моделей, а также разработчикам, ищущим более интерпретируемые и мощные альтернативы автокорреляционным языковым моделям. |",
    "links": [
      {
        "type": "paper",
        "href": "https://ojs.aaai.org/index.php/AAAI/article/download/34696/36851"
      },
      {
        "type": "code",
        "href": "https://github.com/M0RJIQUE/tencdm"
      }
    ]
  },
  {
    "title": "PersonGenSampler",
    "url": "https://github.com/ControlGenAI/PersonGenSampler",
    "desc": "В репозитории представлен код для воспроизведения результатов работы по критическому анализу стратегий семплирования в text-to-image генерации с использованием диффузионных моделей. Авторы подробно рассматривают различные подходы: Mixed, Switching, Multi-stage, Masked sampling, а также сравнивают их с существующими решениями. В частности, предлагается использовать смешение траекторий генерации между концептом и его суперклассом, а также различные способы комбинирования guidance сигналов. В серии экспериментов на датасетах Dreambooth и различных бэкбонах (SD-2, SD-XL, PixArt-alpha) показано, что грамотно выбранная стратегия семплирования может заметно повысить соответствие изображе. Отдельное внимание уделено анализу вычислительных затрат различных методов. Результаты обобщены в виде практического фреймворка для выбора стратегии в зависимости от приоритетов. Работа будет полезна исследователям и инженерам, занимающимся генеративными моделями, а также разработчикам приложений в креативных индустриях и автоматизации контента. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2502.05895"
      },
      {
        "type": "code",
        "href": "https://github.com/ControlGenAI/PersonGenSampler"
      }
    ]
  },
  {
    "title": "Challenges-on-generating-structurally-diverse-graphs",
    "url": "https://github.com/Abusagit/Challenges-on-generating-structurally-diverse-graphs",
    "desc": "В репозитории опубликован код для воспроизведения результатов работы по генерации структурно разнообразных графов. Авторы впервые формализуют и системно исследуют задачу построения наборов графов с максимальным структурным разнообразием — задача, критически важная для тестирования алгоритмов на графах, оценки нейросетевых приближений и построения бенчмарков. В работе подробно анализируется, как определить меру разнообразия для множества графов и почему задача не сводится к стандартным генераторам случайных графов. Введён показатель diversity на основе агрегирования попарных расстояний между графами (Energy), обладающий важными теоретическими свойствами, как монотонность и уникальность. Экспериментально исследованы и сравниваются различные алгоритмы генерации: жадный отбор из большого пула, генетические алгоритмы, локальная оптимизация и нейросетевые генеративные модели. Показано, что предлагаемые методы существенно превосходят классические случайные модели, например, Erdős–Rényi, GraphWorld, по мере diversity, позволяя получать выборки графов с сильно отличающимися характеристиками. Исследование также даёт новые инсайты о свойствах различных метрик расстояния между графами. Работа будет полезна исследователям в области графов, алгоритмистам, а также разработчикам бенчмарков и тестовых наборов для графовых задач. |",
    "links": [
      {
        "type": "paper",
        "href": "https://openreview.net/pdf?id=bbGPoL1NLo"
      },
      {
        "type": "code",
        "href": "https://github.com/Abusagit/Challenges-on-generating-structurally-diverse-graphs"
      }
    ]
  },
  {
    "title": "DVAR",
    "url": "https://github.com/yandex-research/DVAR",
    "desc": "В репозитории опубликован код для воспроизведения результатов работы по ускорению персонализации text-to-image моделей при помощи нового критерия ранней остановки обучения. Авторы анализируют динамику тренировки популярных методов кастомизации, таких как Textual Inversion, DreamBooth и Custom Diffusion, и показывают, что стандартные метрики сходимости не отражают реальный прогресс и часто неинформативны. Ключевой вклад работы — введение критерия Deterministic VARiance Evaluation (DVAR), который позволяет автоматически и гораздо раньше завершать обучение без потери качества результатов. DVAR оценивает стабилизацию детерминированной версии loss на фиксированном наборе данных, что позволяет сократить время обучения до 8 раз. Авторы демонстрируют эффективность подхода на 48 концептах и трёх популярных personalization-методах. Эксперименты показывают, что ранняя остановка по DVAR почти не снижает качество генерации, а также предотвращает переобучение и экономит вычислительные ресурсы. Работа будет полезна исследователям и инженерам, работающим с кастомизацией diffusion-моделей, а также разработчикам инструментов для креативных и промышленных задач генерации изображений. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2302.04841"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/DVAR"
      }
    ]
  },
  {
    "title": "gflownet-tlm",
    "url": "https://github.com/tgritsaev/gflownet-tlm",
    "desc": "В репозитории представлен код для оптимизации обратной стратегии в GFlowNets методом Trajectory Likelihood Maximization. Идея простая: учим обратную стратегию, максимизируя правдоподобие полных траекторий, сэмплированных текущей прямой стратегией; затем обновляем прямую стратегию в эквивалентной задаче soft-RL (энтропийно-регуляризованный MDP) с вознаграждениями, задаваемыми новой обратной политикой. Такой чередующийся шаг легко встраивается в TB/DB/SubTB и офф-полиси RL и закрывает ограничение теории фиксированного обратного прохода, принятой в недавних связках GFlowNets — soft-RL. Авторы также обсуждают практические трюки для стабильности и дают условие сходимости при стабильных обновлениях PB и регрет-минимизации для PF. Эксперименты на Hypergrid, Bit Sequences, QM9 и sEH показывают более быструю сходимость и лучшее mode discovery в сложных и менее структурированных средах, особенно QM9; на сильно структурированной sEH выигрыш скромнее и сопоставим с фиксированным равномерным обратным проходом. Код и обучающие скрипты — открыты. Работа будет полезна исследователям GFlowNets и RL, а также практикам из областей дизайна биомолекул и материалов, где важно эффективно исследовать пространство дискретных объектов пропорционально награде. |",
    "links": [
      {
        "type": "paper",
        "href": "https://openreview.net/forum?id=Xj66fkrlTk"
      },
      {
        "type": "code",
        "href": "https://github.com/tgritsaev/gflownet-tlm?tab=readme-ov-file"
      }
    ]
  },
  {
    "title": "tabpfn-finetuning",
    "url": "https://github.com/yandex-research/tabpfn-finetuning",
    "desc": "В репозитории представлен код для систематического изучения дообучения табличной фундаментальной модели TabPFNv2. Авторы сравнивают различные стратегии адаптации — полный fine-tuning, частичный — последние слои/LayerNorm/голова/эмбеддинги, параметро-эффективные LoRA, а также добавочные числовые эмбеддинги — и показывают, что при корректном подборе гиперпараметров именно полное дообучение даёт наилучший баланс точности и скорости сходимости. Ключевой вывод: после адаптации скалярные произведения запрос–ключ в последнем слое inter-sample внимания лучше согласуются с близостью объектов по целевой переменной; за счёт этого модель точнее собирает предсказание из релевантных контекстных примеров. Практически авторы демонстрируют дообучение на наборах до 1 млн ячеек и до 50 тыс. объектов: на академических i.i.d.-разбиениях затюненая версия достигает или превосходит современный уровень, тогда как на задачах с временным сдвигом и богатыми признаками стабильность ниже и сильные не фундаментальные DL/GBDT бейзлайны иногда предпочтительнее. Дополнительно отмечено: полный fine-tuning сходится быстрее альтернатив; увеличение числа объектов, участвующих в одном градиентном шаге предсказаний, стабильно улучшает качество; ансамбли из нескольких дообученных копий дают дополнительный прирост. Код и конфигурации доступны в открытом виде. Работа будет полезна практикам табличного DL и AutoML, выбирающим стратегию адаптации под конкретные данные, и исследователям, изучающим механизмы in-context-обучения в табличных моделях. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2506.08982"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/tabpfn-finetuning"
      }
    ]
  },
  {
    "title": "FEVERDiagnostics",
    "url": "https://github.com/aschern/FEVERDiagnostics",
    "desc": "В репозитории опубликован код для воспроизведения результатов исследования по автоматической проверке фактов с использованием Википедии. Авторы рассматривают задачу в формате корпуса FEVER, где система должна по запросу находить подтверждающие или опровергающие утверждение отрывки текста. Несмотря на высокий прогресс в области, существующие модели часто совершают ошибки, природа которых оставалась недостаточно понятной. Для решения этой проблемы предложена диагностическая таксономия ошибок, включающая десять категорий: синонимы и антонимы, имена собственные, отрицания, квантификаторы, отношения между объектами, числа и арифметика, время, смысловые выводы, география и перегрузка текста лишними деталями. На основе таксономии создан новый диагностический набор данных, позволяющий выявлять слабые места современных систем. Кроме того, авторы разработали генеративный подход к дополнению обучающих данных: часть примеров создаётся автоматически по правилам, а часть — с помощью языковой модели. Эксперименты показывают, что дообучение на таких данных повышает точность распознавания в сложных категориях и улучшает итоговые результаты на тестовом корпусе FEVER. Работа будет полезна исследователям в области обработки естественного языка, специалистам по проверке фактов и разработчикам систем автоматической модерации контента. |",
    "links": [
      {
        "type": "paper",
        "href": "https://link.springer.com/chapter/10.1007/978-3-031-88708-6_20"
      },
      {
        "type": "code",
        "href": "http://github.com/aschern/FEVERDiagnostics"
      }
    ]
  },
  {
    "title": "tencdm",
    "url": "https://github.com/M0RJIQUE/tencdm",
    "desc": "В репозитории опубликован код для воспроизведения результатов работы по генерации текста с помощью диффузионных моделей. Авторы предлагают новый подход TEncDM, где диффузионная модель обучается не на стандартных векторных представлениях слов (эмбеддингах), а на выходах заранее обученных языковых моделей — так называемых кодировках. В отличие от эмбеддингов, такие кодировки содержат контекст, что облегчает восстановление текста при пошаговом удалении шума. В исследовании подробно анализируются ключевые компоненты диффузионной модели: архитектура декодера, стратегия добавления шума и механизм обуславливания на предыдущий выход - self-conditioning. Авторы показывают, что использование кодировок вместо эмбеддингов существенно повышает качество генерации, а также то, что более сложный декодер, учитывающий контекст, исправляет ошибки и делает текст более связным. Для проверки метода проведены эксперименты на задачах переформулирования вопросов, суммаризации и упрощения текста. Результаты показывают, что TEncDM превосходит существующие неавторегрессионные диффузионные модели и по ряду метрик сравним с классическими авторегрессионными методами. Работа будет полезна исследователям в области обработки текста, специалистам по генеративным моделям и разработчикам систем автоматической генерации контента. |",
    "links": [
      {
        "type": "paper",
        "href": "https://ojs.aaai.org/index.php/AAAI/article/view/34696"
      },
      {
        "type": "code",
        "href": "https://github.com/M0RJIQUE/tencdm"
      }
    ]
  },
  {
    "title": "graphland",
    "url": "https://github.com/yandex-research/graphland",
    "desc": "В репозитории опубликован код и набор данных GraphLand для оценки методов машинного обучения на графах в прикладных промышленных задачах. Авторы отмечают, что большинство существующих бенчмарков ограничены узкой областью, что не отражает реального разнообразия графовых данных. GraphLand включает 14 графовых наборов из разных доменов: веб-графы с задачами предсказания посещаемости сайтов и выявления мошенничества, социальные сети художников и пользователей стриминговых платформ, дорожные сети с прогнозом скорости движения, сервисы отзывов с задачей обнаружения фейковых рецензий, а также данные электронной коммерции и рекламы. Авторы проводят масштабные эксперименты, сравнивая графовые нейронные сети с градиентным бустингом над деревьями решений. Показано, что GNN с механизмом внимания часто превосходят классические архитектуры, однако модели бустинга при расширении признаков за счёт графовой информации становятся сильным бейзлайном, особенно в регрессионных задачах. Также выявлено, что временные сдвиги в распределении данных и динамика графа существенно влияют на качество, что подчёркивает необходимость разработки более устойчивых моделей. Современные универсальные фундаментальные графовые модели продемонстрировали слабые результаты на предложенных наборах данных. Работа будет полезна исследователям в области анализа графов, разработчикам алгоритмов машинного обучения, а также инженерам, работающим с промышленными данными. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/abs/2409.14500"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/graphland"
      }
    ]
  },
  {
    "title": "TwoToInfinity",
    "url": "https://github.com/fallnlove/TwoToInfinity",
    "desc": "В репозитории опубликован код для воспроизведения результатов работы по оценке специальных матричных норм в режиме без явного хранения матрицы. Авторы рассматривают две нормы операторов — от двух к бесконечности и от единицы к двум, которые позволяют контролировать структуру строк и столбцов матриц и широко применяются в теории обучения и регуляризации. Предложены новые случайные алгоритмы TwINEst и его улучшенная версия TwINEst++, которые используют только операции умножения матрицы на вектор и модифицируют классический метод Хатчинсона. Авторы доказывают сходимость и выводят оценки сложности, показывая, что новые методы точнее и устойчивее стандартных степенных итераций, которые могут расходиться. Эксперименты на синтетических и реальных данных демонстрируют эффективность предложенных алгоритмов. В частности, при обучении сверточных сетей на задачах классификации изображений регуляризация на основе двухк-бесконечности нормы улучшает обобщающую способность и повышает устойчивость к атакам. В области рекомендательных систем показано, что метод повышает надёжность моделей UltraGCN к целенаправленным возмущениям. Работа будет полезна исследователям в области численных методов линейной алгебры, специалистам по глубинному обучению и инженерам, разрабатывающим устойчивые рекомендательные системы. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2508.04444v1"
      },
      {
        "type": "code",
        "href": "https://github.com/fallnlove/TwoToInfinity"
      }
    ]
  },
  {
    "title": "G2T-FM",
    "url": "https://github.com/yandex-research/G2T-FM",
    "desc": "В репозитории опубликован код G2T-FM, позволяющего строить простую базовую модель для графов на основе TabPFNv2. Идея заключается в превращении каждой графовой задачи в табличную с добавлением к исходным признакам узлов агрегатов по соседям, классических структурных характеристик графа (степень, PageRank, собственные векторы лапласиана) и обучаемых структурных кодировок PEARL; затем на этих представлениях работает TabPFNv2. Такой конвейер позволяет обрабатывать разнородные признаки узлов и таргета, не ограничиваясь только текстовыми графами. В режиме без дообучения G2T-FM даёт сильные результаты и заметно превосходит доступные открытые бейзлайновые графовые модели; после дообучения модель обгоняет хорошо настроенные GNN, обученные с нуля. Авторы проводят оценку на наборах GraphLand с нетекстовыми признаками и на классических датасетах с текстовыми признаками; показано, что выигрыш обеспечивается сочетанием табличного бэкбона и графовых дополнений к признакам. Работа может быть полезна исследователям графового обучения, инженерам, работающим с промышленными графами и смешанными типами признаков, и командам, которым нужна переносимость между разными графовыми доменами. |",
    "links": [
      {
        "type": "paper",
        "href": "https://arxiv.org/pdf/2508.20906"
      },
      {
        "type": "code",
        "href": "https://github.com/yandex-research/G2T-FM"
      }
    ]
  },
  {
    "title": "multimodal_unlearning",
    "url": "https://github.com/somvy/multimodal_unlearning",
    "desc": "В репозитории опубликован код и данные для воспроизведения результатов работы по удалению информации из мультимодальных моделей — задачам машинного забывания (machine unlearning). Авторы представляют CLEAR: первый открытый бенчмарк для оценки того, насколько модели способны забывать данные одновременно в текстовой и визуальной формах. Набор данных включает сведения о 200 вымышленных авторах, их биографии и 3700 синтетических портретов. Для каждого персонажа предусмотрены пары вопрос–ответ и изображения, что позволяет проверять, как хорошо модель забывает конкретную личность сразу в двух модальностях. Исследование охватывает 11 современных методов разучивания и показывает, что одновременное разучивание обеих модальностей значительно эффективнее, чем по отдельности. Авторы подробно анализируют баланс между удалением лишней информации и сохранением полезных знаний. Показано, что даже лучшие методы (LLMU и DPO) не достигают качества эталонной модели и часто теряют способность к распознаванию или порождению связанного контента. CLEAR также вводит систему показателей для оценки качества забывания, сохранения знаний и устойчивости к утечкам между модальностями. Работа будет полезна исследователям в области защиты данных, разработчикам мультимодальных языковых моделей и специалистам, изучающим этические аспекты ИИ и реализацию права на забвение. |",
    "links": [
      {
        "type": "paper",
        "href": "https://aclanthology.org/2025.findings-acl.1058.pdf"
      },
      {
        "type": "code",
        "href": "https://github.com/somvy/multimodal_unlearning"
      }
    ]
  }
]
